###################### Grundidee #########################

1. Adversarial Examples ausdrucken und testen, ob sie nach Wiederaufnahme immer noch adversarial sind
2. andere Angriffsarten versuchen, die tatsächliche Veränderungen (nicht nur rauschen) verursachen - wahrscheinlich basierend auf dem Expectation over Transformation Framework oder Robust Physical Perturbations
3. Evaluation von Gegenmaßnahmen

##################### Meeting 17.10. #####################


- Vorher normale Schilder ausdrucken und schauen wie gut das Netz die Schilder erkennt als Baseline
- mit Stoppschildern anfangen evtl ein weiteres Schild
- Mal nachschaue welches Format die Bilder haben und mit welchem Drucker und auf welches Material gedruckt wurde

- dann Expectation over Transformation

- Gegenmaßnahme: LogicOOD



########### Fragen ##############
1. wie funktioniert das mit der Größe der Bilder?
 - Auf welcher Größe druckt man sie aus? 64x64? 512x512?
 - Resized man sie, wenn das Modell sie klassifizieren soll?
 => Lösung: Morgilus et al referencing DARTS:
    1. have high-res image and generate mask which include only the sign
    2. resize both mask and image to classifiers input dimensions (32x32).
    3. do adv. attack
    4. resize perturbation and add to original image


############################## Was gemacht? ####################################

1.Versuch

- Bilder auf 1200x1200 auf DIN-A4 ausgedruckt. 
- Die Bilder an die Tür geklebt und mit einem Abstand von 1-4 Metern Fotos gemacht (mit drehen der Kamera) (mitten am Tag - hell)
- Bilder auf MacBook gesendet (airdrop)
- die .HEIC files in png umgewandelt (imagemagick) oder als png angezeigt (pillow_heif)
=> die Qualität war viel zu schlecht, es war viel zu weit weg

Idee: erst mal irgendwie zum Laufen bringen, deshalb einfache Bilder von nah dran
Schwierigkeit: low-res Bilder auf DINA-4 drucken, und dann abfotografieren und dann wieder runterskalieren, damit das Modell das nutzen kann


2. Versuch

- Bilder auf 1200x1200 auf DIN-A4 ausgedruckt. 
- Bilder an die Tür geklebt und von sehr nah (3 Fotos pro Bild aus verschiedenen Weiten ca. 30-50cm entfernt) abfotografieren (Zimmerlicht, weil dunkel)
- Bilder auf MacBook senden (Airdrop)
- die .HEIC files in png umgewandelt (imagemagick) oder als png angezeigt (pillow_heif)
=> besser

Resultat nach Prediction:
- 66% accuracy
- er tut sich schwer mit den Bildern, die etwas weiter weg sind. Von denen, die nah dran sind hat er alle richtig erkannt
- fast alle von denen, die am weitesten weg waren hat er nicht erkannt
- von den mittelweiten hat er manche nicht erkannt

############################ Mask erstellen ###################################

- Anlehnung an https://github.com/evtimovi/


################################# Meeting 04.11. #############################
die Bilder, die weiter weg sind haben evtl zu viel Rand, deswegen:
=> Bilder zurecht croppen - https://github.com/IDEA-Research/GroundingDINO
- gibt bounding boxes zurück

Problem: wenn das funktioniert kann man vielleicht etwas weiter weggehen, aber nicht weit, da Bilder zu low-res

- hochauflösende Bilder aus dem Internet ziehen

- für Masken erstellen: https://github.com/IDEA-Research/Grounded-SAM-2


########################### Grounding DINO #################################

- verschiedene Prompts ausprobiert. Häufig macht er mehrere bounding boxes. verschiedene Thresholds ausprobiert (35 == 40)
- "traffic sing"
- "Foto"
- "only the Photography"
- "only the Paper with the foto on it" mit Box-Threshold ist perfekt
