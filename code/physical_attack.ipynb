{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "inspiriert durch https://github.com/Trusted-AI/adversarial-robustness-toolbox/blob/main/examples/get_started_pytorch.py",
   "id": "a7d31ec2f396767d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-03T09:37:32.530946Z",
     "start_time": "2026-01-03T09:37:32.525928Z"
    }
   },
   "source": [
    "from art.attacks.evasion import GRAPHITEWhiteboxPyTorch\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "from torchvision.transforms import ToTensor, Resize, Compose\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from pytorch_ood.utils import ToRGB\n",
    "from gtsrb import GTSRB\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T10:41:16.938745Z",
     "start_time": "2026-01-03T10:41:16.633561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trans = Compose([\n",
    "            ToRGB(),\n",
    "            ToTensor(),\n",
    "            Resize((64, 64), antialias=True)\n",
    "        ])\n",
    "\n",
    "\n",
    "batch_size = 3\n",
    "test_data = GTSRB(root=\".\", train=False, transforms=trans)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "resnet18_model = torch.load(\"64x64/label-net-resnet18-64.pt\", map_location=\"cpu\", weights_only=False)\n",
    "wideresnet40_model = torch.load(\"64x64/label-net-wrn40-64.pt\", map_location=\"cpu\", weights_only=False)\n",
    "\n",
    "resnet18_model.eval()\n",
    "wideresnet40_model.eval()\n",
    "\n",
    "\n",
    "digital_imgs = Path(\"digital_imgs\")\n",
    "images = []\n",
    "to_tensor = ToTensor()\n",
    "for img in sorted(digital_imgs.glob(\"*.png\")):\n",
    "    img = Image.open(img)\n",
    "    img = img.resize((64, 64))\n",
    "    img_t = to_tensor(img)\n",
    "    images.append(img_t)\n",
    "\n",
    "images = torch.stack(images)\n",
    "labels = [16, 1, 38, 11, 33, 18, 9, 13, 34, 2, 7, 13, 26, 15, 28]\n",
    "labels = np.array(labels)\n",
    "\n",
    "images.size()"
   ],
   "id": "319f1d0094b7a953",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 3, 64, 64])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "testing on original images",
   "id": "7c0e63a68ac66de5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T10:41:19.320188Z",
     "start_time": "2026-01-03T10:41:19.078997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    preds = wideresnet40_model(images).argmax(1)\n",
    "\n",
    "accuracy = (preds == torch.tensor(labels)).float().mean().item()\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ],
   "id": "8a0fe8fb327a3f8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "splitten der Daten in train, val, test (5,5,5)",
   "id": "3b74db5c6c636549"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T10:52:07.064876Z",
     "start_time": "2026-01-03T10:52:07.031460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# vorher mischen, sonst bleibt die Reihenfolge\n",
    "perm = torch.randperm(len(images))\n",
    "images = images[perm]\n",
    "labels = labels[perm.numpy()]\n",
    "\n",
    "# Splits\n",
    "train_imgs, train_labels = images[:5], labels[:5]\n",
    "val_imgs,   val_labels   = images[5:10], labels[5:10]\n",
    "test_imgs,  test_labels  = images[10:], labels[10:]\n",
    "\n",
    "model = resnet18_model\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    clip_values=(0.0, 1.0),\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(3, 64, 64),\n",
    "    nb_classes=43,\n",
    ")\n",
    "\n",
    "#classifier.fit(train_imgs, train_labels, batch_size=batch_size, nb_epochs=3)\n",
    "\n",
    "predictions = classifier.predict(val_imgs)\n",
    "pred_classes = np.argmax(predictions, axis=1)\n",
    "accuracy = np.mean(pred_classes == val_labels)\n",
    "print(f\"Accuracy on benign val examples: {accuracy * 100:.2f}%\")"
   ],
   "id": "34c7884e2f1eadad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on benign val examples: 0.00%\n"
     ]
    }
   ],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
